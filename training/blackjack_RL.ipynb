{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-25T18:42:34.863636Z",
     "start_time": "2026-01-25T18:42:34.860661Z"
    }
   },
   "source": "from environment.blackjack import Blackjack",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T18:42:34.871799Z",
     "start_time": "2026-01-25T18:42:34.870012Z"
    }
   },
   "cell_type": "code",
   "source": "env = Blackjack()",
   "id": "696c52c430375d02",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T18:42:34.877071Z",
     "start_time": "2026-01-25T18:42:34.875402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ],
   "id": "3f6b8dd3c7db50ea",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T18:42:34.883372Z",
     "start_time": "2026-01-25T18:42:34.881404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.accelerator.current_accelerator() if torch.accelerator.is_available else \"cpu\"\n",
    "device = \"cpu\"\n",
    "print(f\"device: {device}\")"
   ],
   "id": "ace024bb36fcd00c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T18:42:34.893735Z",
     "start_time": "2026-01-25T18:42:34.891495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(3, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_norm = x.clone()\n",
    "        x_norm[:, 0] = x[:, 0] / 21.0\n",
    "        x_norm[:, 1] = x[:, 1] / 11.0\n",
    "        logits = self.layers(x_norm)\n",
    "        return logits"
   ],
   "id": "68889bc710400c17",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T18:42:34.903615Z",
     "start_time": "2026-01-25T18:42:34.899905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(11)\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ],
   "id": "c127cfbb37e7a3db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T18:42:34.912030Z",
     "start_time": "2026-01-25T18:42:34.909837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "from collections import deque\n",
    "class ReplayBuffer():\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, min(batch_size, len(self.buffer)))\n",
    "\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)"
   ],
   "id": "f4d285205b92e8ee",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T18:42:34.933484Z",
     "start_time": "2026-01-25T18:42:34.916752Z"
    }
   },
   "cell_type": "code",
   "source": "buffer = ReplayBuffer(100000)",
   "id": "49ef4fdbda778ede",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T18:42:34.937404Z",
     "start_time": "2026-01-25T18:42:34.935811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_action(state, epsilon, double_possible, splittable):\n",
    "    if random.random() < epsilon:\n",
    "        return env.action_random(double_possible, splittable)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        q_values = model(state[:, :3])\n",
    "        if not double_possible:\n",
    "            q_values[:, 2] = -99.0\n",
    "        if not splittable:\n",
    "            q_values[:, 3] = -99.0\n",
    "\n",
    "    return torch.argmax(q_values).item()"
   ],
   "id": "921fed80f900488",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T18:42:34.941156Z",
     "start_time": "2026-01-25T18:42:34.938966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "def training(target_model):\n",
    "    batch = zip(*buffer.sample(batch_size))\n",
    "\n",
    "    state, action, reward, next_state, done = batch\n",
    "\n",
    "    state = torch.stack(state).to(device).squeeze(1)\n",
    "    action = torch.tensor(action).long().unsqueeze(1).to(device)\n",
    "    reward = torch.tensor(reward).float().unsqueeze(1).to(device)\n",
    "    next_state = torch.stack(next_state).to(device).squeeze(1)\n",
    "    done = torch.tensor(done).float().unsqueeze(1).to(device)\n",
    "\n",
    "    output = model(state[:, :3])\n",
    "    label = output.gather(dim=1, index=action)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        target_q_vals = target_model(next_state[:, :3])\n",
    "\n",
    "        action_split = (action[:] == 3) + 1.0\n",
    "        target_q_vals *= action_split\n",
    "\n",
    "        cannot_double = (next_state[:, -2] == 0)\n",
    "        cannot_split = (next_state[:, -1] == 0)\n",
    "\n",
    "        target_q_vals[cannot_double, 2] = -99.0\n",
    "        target_q_vals[cannot_split, 3] = -99.0\n",
    "        future_move = torch.amax(target_q_vals, dim=1).unsqueeze(1)\n",
    "        prediction = reward + (1 - done) * gamma * future_move\n",
    "    loss = F.smooth_l1_loss(label, prediction)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss"
   ],
   "id": "dd1d75a74e902968",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T19:06:57.209741Z",
     "start_time": "2026-01-25T18:55:27.427419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import copy\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "epochs = 1000000\n",
    "batch_size = 128\n",
    "gamma = 1.0\n",
    "epsilon = 1.0\n",
    "target_model = copy.deepcopy(model)\n",
    "model.train()\n",
    "reward_sum = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    state = env.next_hand()\n",
    "\n",
    "    state = torch.tensor(state, device=device).float().unsqueeze(0)\n",
    "    done = False\n",
    "\n",
    "    if epoch % 300 == 0:\n",
    "        target_model.load_state_dict(model.state_dict())\n",
    "\n",
    "    while not done:\n",
    "        double_possible = state[:, -2]\n",
    "        splittable = state[:, -1]\n",
    "\n",
    "        if buffer.size() < 10 * batch_size:\n",
    "            action = env.action_random(double_possible, splittable)\n",
    "        else:\n",
    "            action = get_action(state, epsilon, double_possible, splittable)\n",
    "\n",
    "        next_state, reward, hand_over = env.step(action)\n",
    "        if len(next_state) == 2:\n",
    "            next_state = next_state[0]\n",
    "        next_state = torch.tensor(next_state, device=device).float().unsqueeze(0)\n",
    "\n",
    "        done = hand_over or action == 3\n",
    "\n",
    "        buffer.push(state, action, reward, next_state, hand_over)\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "    reward_sum += reward\n",
    "\n",
    "    if buffer.size() < 10 * batch_size:\n",
    "        continue\n",
    "\n",
    "    loss = training(target_model)\n",
    "\n",
    "    if epoch % 100000 == 0:\n",
    "        print(f\"epoch: {epoch} | reward net: {round(reward_sum)}\")\n",
    "        reward_sum = 0\n",
    "\n",
    "    if epoch < 0.75 * epochs:\n",
    "        epsilon -= 1/(0.75*epochs)\n",
    "    else:\n",
    "        epsilon = 0\n"
   ],
   "id": "c29abad39fbf51b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 | reward net: 1\n",
      "epoch: 100000 | reward net: -50305\n",
      "epoch: 200000 | reward net: -44267\n",
      "epoch: 300000 | reward net: -38855\n",
      "epoch: 400000 | reward net: -32441\n",
      "epoch: 500000 | reward net: -25179\n",
      "epoch: 600000 | reward net: -18555\n",
      "epoch: 700000 | reward net: -11357\n",
      "epoch: 800000 | reward net: -5662\n",
      "epoch: 900000 | reward net: -5165\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T19:38:31.219754Z",
     "start_time": "2026-01-25T19:38:31.214652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "state = env.next_hand()\n",
    "state = (8, 5, 0)\n",
    "print(state)\n",
    "state = torch.tensor(state, device=device).float().unsqueeze(0)\n",
    "output = model(state)\n",
    "print(output)\n",
    "action = torch.argmax(output).item()"
   ],
   "id": "177abaf744ed591f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 5, 0)\n",
      "tensor([[-2.4521,  0.1884,  0.6103, -0.7789]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T19:10:49.479493Z",
     "start_time": "2026-01-25T19:10:42.945669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "games = 100000\n",
    "model.eval()\n",
    "wins = 0\n",
    "draws = 0\n",
    "losses = 0\n",
    "net_score = 0\n",
    "for game in range(games):\n",
    "    state = env.next_hand()\n",
    "    state = torch.tensor(state, device=device).float().unsqueeze(0)\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            q_values = model(state[:, :3])\n",
    "            if state[0, -2] == 0:\n",
    "                q_values[0, -2] = -99\n",
    "            if state[0, -1] == 0:\n",
    "                q_values[0, -1] = -99\n",
    "\n",
    "            action = torch.argmax(q_values).item()\n",
    "\n",
    "        if action == 3:\n",
    "            _ = env.step(action)\n",
    "            next_state = env.next_hand()\n",
    "            terminated = False\n",
    "\n",
    "        else:\n",
    "            next_state, reward, terminated = env.step(action)\n",
    "\n",
    "        next_state = torch.tensor(next_state, device=device).float().unsqueeze(0)\n",
    "\n",
    "        done = terminated\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "    if reward > 0:\n",
    "        wins += 1\n",
    "    elif reward == 0:\n",
    "        draws += 1\n",
    "    else:\n",
    "        losses += 1\n",
    "\n",
    "    net_score += reward\n",
    "\n",
    "print(f\"Wins: {wins} | Draws: {draws} | Losses: {losses}\")\n",
    "print(f\"Win Accuracy: {(wins/games)*100:.2f}% | Draw Accuracy: {(draws/games)*100:.2f}% | Loss Accuracy: {(losses/games)*100:.2f}%\")\n",
    "print(f\"Net Score: {net_score}\")"
   ],
   "id": "50e09d818b7e1286",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins: 41692 | Draws: 9024 | Losses: 49284\n",
      "Win Accuracy: 41.69% | Draw Accuracy: 9.02% | Loss Accuracy: 49.28%\n",
      "Net Score: -4804.0\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T19:39:31.626749Z",
     "start_time": "2026-01-25T19:39:31.619508Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), \"blackjack_model_weights.pth\")",
   "id": "f7209e2808724c79",
   "outputs": [],
   "execution_count": 87
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
